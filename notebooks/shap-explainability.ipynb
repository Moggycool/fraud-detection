{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a52d74c",
   "metadata": {},
   "source": [
    "# Task 3: Model Explainability with SHAP\n",
    "\n",
    "## Objective\n",
    "\n",
    "Interpret the best fraud detection model using built-in feature importance and SHAP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b308a1",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Load Model, Preprocessor & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fraud Detection Explainability Analysis\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.explainability import (\n",
    "    plot_builtin_feature_importance,\n",
    "    compute_shap_values,\n",
    "    plot_shap_summary,\n",
    "    plot_shap_force,\n",
    "    get_test_case_indices\n",
    ")\n",
    "# Load pre-fitted model and preprocessor\n",
    "model = joblib.load(\"../models/best_rf_model.joblib\")\n",
    "preprocessor = joblib.load(\"../models/preprocessor.joblib\")\n",
    "\n",
    "# Load test data - adjust path as needed\n",
    "df_test = pd.read_csv(\"../data/processed/fraud_test.csv\")\n",
    "X_test = preprocessor.transform(df_test.drop(columns=[\"class\"]))\n",
    "y_test = df_test[\"class\"].values\n",
    "\n",
    "# *(Optional)*: Get correct feature names after transformation\n",
    "try:\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "except AttributeError:\n",
    "    feature_names = [f\"f_{i}\" for i in range(X_test.shape[1])]\n",
    "\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516e959",
   "metadata": {},
   "source": [
    "## 2. Built-in Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64414eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 2. Built-in Feature Importance\n",
    "plot_builtin_feature_importance(model, feature_names, top_n=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac221c3",
   "metadata": {},
   "source": [
    "## 3. SHAP Global Importance (Summary Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. SHAP Global Explanation (Summary Plot)\n",
    "# SHAP can be slow, subsample if needed for large datasets\n",
    "N = 500\n",
    "X_shap = X_test if X_test.shape[0] < N else X_test[:N]\n",
    "explainer, shap_values = compute_shap_values(model, X_shap, model_type=\"tree\")\n",
    "\n",
    "# SHAP summary plot (global view)\n",
    "plot_shap_summary(shap_values, X_shap, feature_names=feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85365245",
   "metadata": {},
   "source": [
    "# 4. SHAP Local Explanation (Force Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#4. SHAP Local Explanation (Force Plots)\n",
    "# Run predictions for picking test cases\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Get indices for one TP, FP, FN\n",
    "case_indices = get_test_case_indices(y_test, y_pred)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# Force plot for True Positive\n",
    "if case_indices[\"TP\"] is not None:\n",
    "    print(\"SHAP Force Plot: True Positive\")\n",
    "    plot_shap_force(explainer, shap_values, X_shap, sample_idx=case_indices[\"TP\"], feature_names=feature_names)\n",
    "\n",
    "# Force plot for False Positive\n",
    "if case_indices[\"FP\"] is not None:\n",
    "    print(\"SHAP Force Plot: False Positive\")\n",
    "    plot_shap_force(explainer, shap_values, X_shap, sample_idx=case_indices[\"FP\"], feature_names=feature_names)\n",
    "\n",
    "# Force plot for False Negative\n",
    "if case_indices[\"FN\"] is not None:\n",
    "    print(\"SHAP Force Plot: False Negative\")\n",
    "    plot_shap_force(explainer, shap_values, X_shap, sample_idx=case_indices[\"FN\"], feature_names=feature_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec6748",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5. Interpretation\n",
    "\n",
    "- Compare built-in feature importances and SHAP summary plot.\n",
    "- List top 5 features (\"drivers\") of fraud predictions by SHAP.\n",
    "- Explain any surprising findings.\n",
    "\n",
    "*(You can use code to extract top SHAP features if you wish:)*\n",
    "\n",
    "# Example: average absolute SHAP value per feature\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "top5_idx = np.argsort(mean_abs_shap)[::-1][:5]\n",
    "for i in top5_idx:\n",
    "    print(f\"{feature_names[i]}: {mean_abs_shap[i]:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a2dbd",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Business Recommendations\n",
    "\n",
    "- List at least 3 actionable recommendations, each referencing specific SHAP findings.\n",
    "  - Example: \"Transactions within 2 hours of signup (as shown by high SHAP impact of 'time_since_signup') should get additional OTP verification.\"\n",
    "- Connect SHAP insights and plots directly to real-world policy or intervention ideas.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
