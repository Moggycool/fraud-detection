{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "051c043e",
         "metadata": {},
         "source": [
            "# Feature Engineering for Fraud Detection\n",
            "\n",
            "## Objective\n",
            "This notebook creates behavioral, temporal, and geolocation features\n",
            "to enhance fraud detection performance.\n",
            "## Feature Engineering Strategy\n",
            "\n",
            "- Time-based features capture suspicious transaction timing.\n",
            "- Velocity features detect automated or scripted behavior.\n",
            "- Country features capture geo-risk patterns.\n",
            "- No target leakage features are introduced.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "8d3200a4",
         "metadata": {},
         "source": [
            "üåç IP ‚Üí Country Merge\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5596d41f",
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# Fraud Detection Feature Engineering Pipeline\n",
            "# Allow imports from src/\n",
            "import sys\n",
            "from pathlib import Path\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "PROJECT_ROOT = Path(\"..\").resolve()\n",
            "if str(PROJECT_ROOT) not in sys.path:\n",
            "    sys.path.insert(0, str(PROJECT_ROOT))\n",
            "\n",
            "from src.data_loader import load_fraud_data, load_ip_country_data\n",
            "from src.preprocessing import clean_fraud_data\n",
            "\n",
            "\n",
            "# Load raw data\n",
            "df = load_fraud_data(\"../data/raw/Fraud_Data.csv\")\n",
            "ip_df = load_ip_country_data(\"../data/raw/IpAddress_to_Country.csv\")\n",
            "\n",
            "# Clean fraud data\n",
            "df = clean_fraud_data(df)\n",
            "\n",
            "df.head()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "db3d0cf8",
         "metadata": {},
         "outputs": [],
         "source": [
            "from src.geo_utils import convert_ip_to_int, merge_ip_country\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fraud_df = convert_ip_to_int(df)\n",
            "fraud_df = merge_ip_country(fraud_df, ip_df)\n",
            "print(fraud_df.head())\n",
            "\n",
            "fraud_df[[\"ip_address\", \"ip_int\", \"country\"]].head()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "2cf24426",
         "metadata": {},
         "source": [
            "Mapping IP addresses to countries enables the detection\n",
            "of geographically anomalous transactions.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "36ed04e4",
         "metadata": {},
         "source": [
            "‚öôÔ∏è Time & Velocity Features"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "4892727a",
         "metadata": {},
         "outputs": [],
         "source": [
            "#üïí Time-Based Features\n",
            "from src.feature_engineering import add_time_features, add_transaction_velocity\n",
            "\n",
            "fraud_df = add_time_features(fraud_df)\n",
            "fraud_df = add_transaction_velocity(fraud_df)\n",
            "fraud_df[[\"hour_of_day\", \"day_of_week\", \"time_since_signup\"]].head()\n",
            "\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "import numpy as np\n",
            "\n",
            "# Create a 2x2 subplot layout\n",
            "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
            "fig.suptitle(\"Distribution of Engineered Time-Based Features\", fontsize=18)\n",
            "\n",
            "# 1Ô∏è‚É£ Time Since Signup (log-scaled)\n",
            "sns.histplot(\n",
            "    fraud_df[\"time_since_signup\"],\n",
            "    bins=50,\n",
            "    log_scale=True,\n",
            "    ax=axes[0, 0],\n",
            "    kde=True\n",
            ")\n",
            "axes[0, 0].set_title(\"Time Since Signup (seconds, log scale)\")\n",
            "axes[0, 0].set_xlabel(\"Seconds\")\n",
            "axes[0, 0].set_ylabel(\"Count\")\n",
            "\n",
            "# 2Ô∏è‚É£ Hour of Day\n",
            "sns.countplot(\n",
            "    x=\"hour_of_day\",\n",
            "    data=fraud_df,\n",
            "    ax=axes[0, 1]\n",
            ")\n",
            "axes[0, 1].set_title(\"Transaction Hour of Day\")\n",
            "axes[0, 1].set_xlabel(\"Hour (0‚Äì23)\")\n",
            "axes[0, 1].set_ylabel(\"Count\")\n",
            "\n",
            "# 3Ô∏è‚É£ Day of Week\n",
            "sns.countplot(\n",
            "    x=\"day_of_week\",\n",
            "    data=fraud_df,\n",
            "    ax=axes[1, 0]\n",
            ")\n",
            "axes[1, 0].set_title(\"Transaction Day of Week\")\n",
            "axes[1, 0].set_xlabel(\"Day (0=Mon, 6=Sun)\")\n",
            "axes[1, 0].set_ylabel(\"Count\")\n",
            "\n",
            "# 4Ô∏è‚É£ Weekend Indicator\n",
            "sns.countplot(\n",
            "    x=\"is_weekend\",\n",
            "    data=fraud_df,\n",
            "    ax=axes[1, 1]\n",
            ")\n",
            "axes[1, 1].set_title(\"Weekend vs Weekday Transactions\")\n",
            "axes[1, 1].set_xlabel(\"Is Weekend (1 = Yes, 0 = No)\")\n",
            "axes[1, 1].set_ylabel(\"Count\")\n",
            "\n",
            "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
            "plt.show()\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "63cee79a",
         "metadata": {},
         "source": [
            "Time-based features capture behavioral patterns,\n",
            "such as fraud occurring late at night or soon after signup."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "4252bc3a",
         "metadata": {},
         "outputs": [],
         "source": [
            "# -------------------------------------------------------\n",
            "# Transaction velocity feature handling (safe + clean)\n",
            "# -------------------------------------------------------\n",
            "\n",
            "REQUIRED_VELOCITY_COLS = {\"transactions_last_1H\", \"transactions_last_24H\"}\n",
            "\n",
            "# Add velocity features only if missing\n",
            "if not REQUIRED_VELOCITY_COLS.issubset(fraud_df.columns):\n",
            "    fraud_df = add_transaction_velocity(fraud_df)\n",
            "\n",
            "# Remove any accidental suffixed duplicates from prior merges\n",
            "dup_cols = [\n",
            "    c for c in fraud_df.columns\n",
            "    if (\"transactions_last\" in c) and c.endswith((\"_x\", \"_y\"))\n",
            "]\n",
            "if dup_cols:\n",
            "    fraud_df = fraud_df.drop(columns=dup_cols)\n",
            "    \n",
            "    \n",
            "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
            "\n",
            "# -------------------------------------------------------\n",
            "# Transactions in last 1 hour (log-scaled)\n",
            "# -------------------------------------------------------\n",
            "sns.histplot(\n",
            "    fraud_df[\"transactions_last_1H\"],\n",
            "    bins=40,\n",
            "    log_scale=True,\n",
            "    ax=axes[0]\n",
            ")\n",
            "axes[0].set_title(\"Log-Scaled Distribution: Transactions in Last 1 Hour\")\n",
            "axes[0].set_xlabel(\"Transaction Count (log scale)\")\n",
            "axes[0].set_ylabel(\"Frequency\")\n",
            "\n",
            "# -------------------------------------------------------\n",
            "# Transactions in last 24 hours (log-scaled)\n",
            "# -------------------------------------------------------\n",
            "sns.histplot(\n",
            "    fraud_df[\"transactions_last_24H\"],\n",
            "    bins=40,\n",
            "    log_scale=True,\n",
            "    ax=axes[1]\n",
            ")\n",
            "axes[1].set_title(\"Log-Scaled Distribution: Transactions in Last 24 Hours\")\n",
            "axes[1].set_xlabel(\"Transaction Count (log scale)\")\n",
            "axes[1].set_ylabel(\"Frequency\")\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.show()\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "# Sanity check\n",
            "fraud_df[list(REQUIRED_VELOCITY_COLS)].head()\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "ff47326d",
         "metadata": {},
         "source": [
            "Fraud often occurs in bursts.\n",
            "Velocity features quantify rapid transaction activity,\n",
            "which is uncommon for legitimate users.\n",
            "\n",
            "Numerical features will be scaled using StandardScaler\n",
            "to support distance-based and gradient-based models.\n",
            "Scaling is not applied to PCA features in the credit card dataset.\n",
            "\n",
            "Both datasets exhibit severe class imbalance.\n",
            "Resampling techniques such as SMOTE will be applied\n",
            "only to training data during modeling to avoid information leakage.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "f77c5e9b",
         "metadata": {},
         "source": [
            "üíæ Save Processed Data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d17e379c",
         "metadata": {},
         "outputs": [],
         "source": [
            "# -------------------------------------------------------\n",
            "# Compare transaction velocity by fraud class (KEY INSIGHT)\n",
            "# -------------------------------------------------------\n",
            "\n",
            "plt.figure(figsize=(8, 5))\n",
            "\n",
            "sns.boxplot(\n",
            "    x=\"class\",\n",
            "    y=\"transactions_last_24H\",\n",
            "    data=fraud_df\n",
            ")\n",
            "\n",
            "plt.yscale(\"log\")\n",
            "plt.title(\"Transaction Velocity (Last 24 Hours) by Fraud Class\")\n",
            "plt.xlabel(\"Fraud Label (0 = Legitimate, 1 = Fraud)\")\n",
            "plt.ylabel(\"Transactions in Last 24 Hours (log scale)\")\n",
            "\n",
            "plt.show()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "074b129a",
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "#üíæ Save Processed Data\n",
            "fraud_df.to_csv(\"../data/processed/fraud_data_features.csv\", index=False)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c37a8012",
         "metadata": {},
         "source": [
            "## Model-Ready Preprocessing Pipeline\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "438975fa",
         "metadata": {},
         "source": [
            "Feature / Target Separation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "2b0ecd6e",
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# Datetime conversion\n",
            "df[\"signup_time\"] = pd.to_datetime(df[\"signup_time\"])\n",
            "df[\"purchase_time\"] = pd.to_datetime(df[\"purchase_time\"])\n",
            "\n",
            "# Time since signup (hours)\n",
            "df[\"time_since_signup\"] = (\n",
            "    (df[\"purchase_time\"] - df[\"signup_time\"])\n",
            "    .dt.total_seconds() / 3600\n",
            ")\n",
            "\n",
            "# OPTIONAL: velocity feature (skip if not ready)\n",
            "# df[\"transactions_last_24h\"] = ...\n",
            "\n",
            "#assert \"time_since_signup\" in df.columns\n",
            "# assert \"transactions_last_24h\" in df.columns\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e7fed42c",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(\"DataFrame used for modeling:\")\n",
            "print(df.columns)\n",
            "\n",
            "X = df.drop(columns=[\"class\"])\n",
            "y = df[\"class\"]\n",
            "\n",
            "print(X.columns)\n",
            "print(y.name)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f688fa1b",
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(\n",
            "    X,\n",
            "    y,\n",
            "    test_size=0.2,\n",
            "    stratify=y,\n",
            "    random_state=42\n",
            ")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9a0be675",
         "metadata": {},
         "source": [
            "Feature Type Identification"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "a549ecc0",
         "metadata": {},
         "outputs": [],
         "source": [
            "num_features = [\n",
            "    \"purchase_value\",\n",
            "    \"time_since_signup\",\n",
            "    \"age\"\n",
            "]\n",
            "\n",
            "cat_features = [\n",
            "    \"browser\",\n",
            "    \"source\",\n",
            "    \"sex\"\n",
            "]\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fc4fb422",
         "metadata": {},
         "outputs": [],
         "source": [
            "required_features = num_features + cat_features\n",
            "missing = [c for c in required_features if c not in X_train.columns]\n",
            "assert not missing, f\"Missing features: {missing}\"\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "568630e8",
         "metadata": {},
         "source": [
            "Scaling & Encoding Pipeline"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "129a147f",
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.compose import ColumnTransformer\n",
            "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
            "from sklearn.pipeline import Pipeline\n",
            "\n",
            "\n",
            "numeric_transformer = Pipeline(steps=[\n",
            "    (\"scaler\", StandardScaler())\n",
            "])\n",
            "\n",
            "categorical_transformer = Pipeline(steps=[\n",
            "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
            "])\n",
            "\n",
            "preprocessor = ColumnTransformer(\n",
            "    transformers=[\n",
            "        (\"num\", numeric_transformer, num_features),\n",
            "        (\"cat\", categorical_transformer, cat_features)\n",
            "    ]\n",
            ")\n",
            "print(df.columns)# Ensure datetime types\n",
            "df[\"signup_time\"] = pd.to_datetime(df[\"signup_time\"])\n",
            "df[\"purchase_time\"] = pd.to_datetime(df[\"purchase_time\"])\n",
            "\n",
            "# Time since signup (in hours)\n",
            "df[\"time_since_signup\"] = (\n",
            "    (df[\"purchase_time\"] - df[\"signup_time\"])\n",
            "    .dt.total_seconds() / 3600\n",
            ")\n",
            "\n",
            "df[\"time_since_signup\"].describe()\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5d456bfa",
         "metadata": {},
         "outputs": [],
         "source": [
            "X_train_processed = preprocessor.fit_transform(X_train)\n",
            "X_test_processed = preprocessor.transform(X_test)\n",
            "\n",
            "print(X_train_processed.shape)\n",
            "print(X_test_processed.shape)\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "64472288",
         "metadata": {},
         "source": [
            "Train/Test Split (BEFORE SMOTE)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "eee16f7e",
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(\n",
            "    X,\n",
            "    y,\n",
            "    test_size=0.2,\n",
            "    stratify=y,\n",
            "    random_state=42\n",
            ")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c87d575c",
         "metadata": {},
         "source": [
            "Apply Scaling & Encoding"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f194270e",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(\"Numeric features expected by pipeline:\", num_features)\n",
            "print(\"Columns actually in X_train:\", list(X_train.columns))\n",
            "print(\"Columns actually in X_test:\", list(X_test.columns))\n",
            "\n",
            "X_train_processed = preprocessor.fit_transform(X_train)\n",
            "X_test_processed = preprocessor.transform(X_test)\n",
            "\n",
            "print(X_train.columns)\n",
            "print(X_test.columns)\n",
            "\n",
            "print(X_train_processed.shape)\n",
            "print(X_test_processed.shape)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a0360ee2",
         "metadata": {},
         "source": [
            "Class Imbalance Handling (SMOTE)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "46505342",
         "metadata": {},
         "outputs": [],
         "source": [
            "from imblearn.over_sampling import SMOTE\n",
            "\n",
            "smote = SMOTE(random_state=42)\n",
            "\n",
            "X_train_resampled, y_train_resampled = smote.fit_resample(\n",
            "    X_train_processed,\n",
            "    y_train\n",
            ")\n",
            "\n",
            "\n",
            "print(\"Before SMOTE:\")\n",
            "print(y_train.value_counts(normalize=True))\n",
            "\n",
            "print(\"\\nAfter SMOTE:\")\n",
            "print(pd.Series(y_train_resampled).value_counts(normalize=True))\n",
            "print(X_train_resampled.shape)\n",
            "print(y_train_resampled.shape)\n",
            "# Save Processed and Resampled Data\n",
            "np.save(\"../data/processed/X_train.npy\", X_train_resampled)\n",
            "np.save(\"../data/processed/y_train.npy\", y_train_resampled)\n",
            "np.save(\"../data/processed/X_test.npy\", X_test_processed)\n",
            "np.save(\"../data/processed/y_test.npy\", y_test)\n",
            "# EDA of Fraud Data\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "myenv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.13.9"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
